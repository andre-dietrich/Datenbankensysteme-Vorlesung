<!--
author:   AndrÃ© Dietrich; GitHub CoPilot
language: de
narrator: German Male
comment:  Grundlagen der Datenspeicherung: Von der DIKW-Pyramide (Daten â†’ Informationen â†’ Wissen â†’ Weisheit) Ã¼ber Serialisierungsformate (CSV, JSON, YAML, XML) bis zur praktischen Motivation fÃ¼r Datenbanksysteme. Hands-on Ad-hoc-Analyse von CSV/JSON-Daten direkt im Browser.

logo:     ../assets/img/logo/1-lecture.jpg

edit:     true

import: https://raw.githubusercontent.com/liaTemplates/PyScript/main/README.md
        https://raw.githubusercontent.com/LiaScript/CodeRunner/master/README.md
-->




# Daten & Serialisierung + DIKW + Vergleichsachsen Teaser

    --{{0}}--
Willkommen zu "Databases Unlocked" â€“ einer strukturierten Reise durch die Evolutionsstufen der Datenspeicherung! Heute starten wir bewusst "unten" bei rohen Datenformaten, um zu verstehen, warum heutige Systeme so gestaltet sind, wie sie sind.

    {{0-1}}
<section>

**Was Sie heute erwartet:**

> Diese Vorlesung ist **kein nostalgischer RÃ¼ckblick**, sondern die **BegrÃ¼ndung** dafÃ¼r, warum moderne Datenbanksysteme so funktionieren, wie sie funktionieren.

</section>

    --{{1}}--
Lassen Sie uns die Reise durch die Datenspeicher-Paradigmen skizzieren â€“ von primitiv bis hochentwickelt. Wir durchlaufen sieben BlÃ¶cke, wobei jeder Block auf den SchwÃ¤chen des vorherigen aufbaut. Block 1 zeigt uns die rohe RealitÃ¤t: Serialisierungsformate sind einfach, aber fehleranfÃ¤llig. Die BlÃ¶cke 2 bis 6 fÃ¼hren uns durch verschiedene Paradigmen â€“ vom kompakten Paradigmen-Ãœberblick Ã¼ber den relationalen Kern (Algebra, SQL, Performance) bis zu fortgeschrittenen Konzepten. Block 7 vereint schlieÃŸlich Graph-Datenbanken und polyglotte Architekturen mit verteilten Systemen.

    {{1}}
<section>

## ğŸ—ºï¸ Unsere Reise durch die Datenspeicher-Evolution

**Block 1: Die rohe RealitÃ¤t**

- ğŸ“„ **Daten & Serialisierung** â† *Heute: L1*
- ï¿½ï¸ **Paradigmen-Ãœberblick** (L2â€“L6: KV, Document, Wide Column, Column, Trade-offs)

**Block 2: Relationale Grundlagen**

- ğŸ›ï¸ **Relationale Algebra & SQL Basics** (L7â€“L9 + Exercises)
- ğŸ“ **FROM Ïƒ, Ï€, â¨ TO SELECT, JOIN, CTE**

**Block 3: Relationale IntegritÃ¤t**

- ï¿½ **Normalisierung & Constraints** (L10â€“L11)
- âš›ï¸ **Transaktionen & ACID** (L12 + Exercise)

**Block 4: Performance & Optimierung**

- âš¡ **Indexe & Query-Optimierung** (L13â€“L15 + Exercise)
- ğŸ“Š **B-Trees, EXPLAIN, Materialized Views**

**Block 5: Fortgeschrittene Konzepte**

- ğŸ”„ **Locking vs. MVCC** (L16)
- ï¿½ **Views, Triggers, Stored Procedures** (L17)

**Block 6: Graph & Polyglot**

- ğŸ•¸ï¸ **Graph Databases** (L18 + Exercise)
- ğŸ¯ **Property Graphs, Traversal, Pattern Matching**

**Block 7: Polyglot & Verteilung**

- ğŸŒ **Polyglot Persistence** (L19: CQRS, Event Sourcing)
- â˜ï¸ **Verteilte Systeme** (L20â€“L21: Replikation, CAP, Konsistenz)

</section>


    --{{2}}--
Begleitend durchlaufen Sie ein Mini-Projekt mit dokumentierten Designentscheidungen â€“ von rohen CSV-Dateien bis zur polyglotten Architektur. Diese vier Meilensteine sind keine theoretischen Ãœbungen, sondern praktische Erfahrungen mit echten Trade-offs. Meilenstein 1 konfrontiert Sie mit den Limitationen flacher Dateien. Meilenstein 2 zwingt Sie zur Schema-Evolution â€“ was passiert, wenn sich Anforderungen Ã¤ndern? Meilenstein 3 bringt Performance ins Spiel: Wann lohnt sich ein Index wirklich? Und Meilenstein 4 stellt die groÃŸe Frage: Wann rechtfertigt Normalisierung ihren Aufwand? Die Micro-Consistency Checks sind Ihre Reflexionsmomente â€“ explizite Pausen, um Ihr mentales Modell zu kalibrieren.

    {{2}}
<section>

## ğŸ› ï¸ Hands-on: Mini-Projekt & Reflexion

**4 Meilensteine** begleiten unsere Reise:

- **MS1:** Rohdaten + Key-Value Layer
- **MS2:** Document Migration + Schema-Evolution  
- **MS3:** Column Analytics + Performance-Benchmarks
- **MS4:** Relationales Redesign + Index-Strategien

Plus **Micro-Consistency Checks** nach jedem Block:
*"Was glaube ich jetzt â€“ und was hat sich seit Block X verschoben?"*

</section>

    --{{3}}--
Am Ende verfÃ¼gen Sie Ã¼ber ein begrÃ¼ndbares Entscheidungsrepertoire: Sie kÃ¶nnen AnwendungsfÃ¤lle auf Paradigmen abbilden, Trade-offs artikulieren und Risiken antizipieren. Das ist der Unterschied zwischen einem SQL-Kurs und einem Architektur-Kompass. Ein SQL-Kurs lehrt Syntax â€“ `SELECT * FROM table`. Ein Architektur-Kompass lehrt Entscheidungsfindung: "FÃ¼r Session-Storage brauche ich $O(1)$ Zugriff und TTL-Support â€“ also Key-Value. FÃ¼r Beziehungsanalyse brauche ich Traversierung â€“ also Graph. FÃ¼r Reportings brauche ich Aggregationen Ã¼ber Millionen Zeilen â€“ also Column Store." Sie lernen nicht nur Tools, sondern wann und warum Sie sie einsetzen. Das ist polyglotte Denkweise: das richtige Werkzeug fÃ¼r den richtigen Job.

    {{3}}
<section>

## ğŸ§­ Ihr Kompass fÃ¼r datengetriebene Architektur

- âœ… **Trade-off VerstÃ¤ndnis:** Wann nutze ich was?
- âœ… **Risiko-Antizipation:** Schema Drift, Lock Contention, ReplikationsverzÃ¶gerung
- âœ… **Architektur-Entscheidungen:** Sessions vs. Metriken vs. Beziehungsanalyse
- âœ… **Polyglot Thinking:** Das richtige Tool fÃ¼r den richtigen Job

> **Heute:** Wir starten mit der Frage: "Was sind eigentlich Daten?" ğŸª¶

</section>

## Was sind Daten ğŸª¶ğŸª¶ğŸª¶

    --{{0}}--
Bevor wir uns in CSV-Dateien und JSON-Objekte stÃ¼rzen, machen wir einen fundamentalen Schritt zurÃ¼ck: Was sind eigentlich Daten? Diese Frage ist nicht philosophisch gemeint, sondern praktisch.

    {{1}}
<section>

### Daten

    --{{1}}--
Daten sind die rohe, uninterpretierte Ebene. Pixel, Bytes, Zeichen â€“ alles ohne Kontext oder Bedeutung. In Datenbanken entspricht das den puren Feldwerten: "42", "Schmidt", "2023-10-03". Schauen Sie sich dieses Bild an und beschreiben Sie nur das, was Sie sehen â€“ ohne zu interpretieren, was es bedeuten kÃ¶nnte.

Daten kÃ¶nnen strukturiert oder unstrukturiert vorliegen, die zur Beschreibung von Objekten, Ereignissen oder ZustÃ¤nden verwendet werden. Sie kÃ¶nnen in verschiedenen Formaten vorliegen.

    {{2}}
<div>
__Beispiel:__

Was sehen Sie? Beschreiben Sie das folgende Bild mÃ¶glichst detailliert:

![Native American](../assets/img/native-american.jpg "Abb.: Plains-Krieger mit traditionellem Federkopfschmuck -- erstellt mit ChatGPT")

<!---
Prompt:

Create a respectful, historically accurate portrait of a Plains Native American warrior from the 1870s. The man should be in his late 30s to early 40s, with a weathered, experienced face showing wisdom and strength. He has traditional red and white war paint stripes on his cheekbones, long black hair in braids, and intense dark eyes. The elaborate feather headdress is the focal point, containing exactly these elements in specific arrangement:

- Seven golden eagle feathers standing upright in the back, each with distinctive white tips
- Three red-tailed hawk feathers positioned diagonally to the left, with thin red leather wrapping
- Two great horned owl feathers hanging down on the right side, with black leather bands
- One crow feather positioned centrally in front, pure black with a bright yellow rawhide ring
- A horsehair roach (scalp lock) at the crown center
- A brown leather headband with exactly twelve knife notches carved along the edge

The warrior wears traditional buckskin clothing with fringe and a bear claw necklace. The setting should be a soft-focus prairie landscape with warm, golden hour lighting. The image should be in 16 to 9 format, photorealistic and respectful, avoiding any stereotypes or inaccurate cultural elements.
--->

</div>

</section>

    --{{2}}--
Sie haben vermutlich Federn gezÃ¤hlt, Farben benannt, Materialien identifiziert. Das sind die Rohdaten â€“ messbar, zÃ¤hlbar, objektiv. Aber was bedeuten sie? Hier kommen Informationen ins Spiel.

    {{3}}
<section>

### Informationen

    --{{3}}--
Informationen entstehen, wenn wir Daten Kontext und Bedeutung geben. Die sieben Adlerfedern sind nicht nur "sieben gelbe Objekte" â€“ sie sind kodierte Nachrichten mit spezifischer kultureller Bedeutung. In Datenbanken entspricht das der semantischen Ebene: Ein Feld "salary" mit Wert "50000" wird zur Information "Jahresgehalt: 50.000 Euro". Schauen Sie, wie sich rohe Beobachtungen in bedeutungsvolle Nachrichten verwandeln:

__Moment mal, was bedeutet das alles?__

- **Adlerfeder aufrecht:** Tapferkeit im Kampf (eine Feder je getÃ¶tetem Feind)
- **Falkenfeder schrÃ¤g-links + rot:** Geschicklichkeit und Schnelligkeit (eine Feder je erfolgreichem Ãœberraschungsangriff)
- **Eulenfeder hÃ¤ngend + schwarz:** Weisheit und Nachtsicht (eine Feder je Ã¼berlebter Nachtschlacht)
- **KrÃ¤henfeder zentral:** Intelligenz und AnpassungsfÃ¤higkeit (eine Feder je erfolgreich gelÃ¶stem Problem)
- **Lederband mit Kerben:** Lebensjahre und Erfahrungen (eine Kerbe je Lebensjahr)
- **Pferdehaarknoten:** Mindestens ein erbeutetes Pferd

</section>


    {{4}}
<section>

### Wissen

    --{{4}}--
Jetzt haben wir einzelne Bedeutungen, aber noch keine Gesamtsicht. Wissen entsteht, wenn wir Informationen systematisch verknÃ¼pfen und Muster erkennen.
Die Anordnung und Anzahl der Federn, die Farben und Lederbandkerben sind kein Zufall â€“ sie folgen einem kohÃ¤renten System zur Kodierung von Lebenserfahrungen. In Datenbanken entspricht das den Queries, die Beziehungen aufdecken: "Welche Kunden kaufen zusammen?" oder "Welche Faktoren korrelieren mit Erfolg?" Das Wissen liegt in den erkannten ZusammenhÃ¤ngen.

Die Anordnung und Anzahl der Federn, die Farben und die Lederbandkerben sind keine zufÃ¤lligen Dekorationen, sondern kodieren spezifische Informationen Ã¼ber die Errungenschaften, FÃ¤higkeiten und das Alter des Kriegers. Ein erfahrener Krieger mit vielen Federn und Kerben erzÃ¤hlt eine Geschichte von Mut, Geschicklichkeit, Weisheit und einem langen Leben voller Herausforderungen und Siege.

</section>

    --{{5}}--
Aber Wissen allein reicht nicht. Weisheit entsteht, wenn wir aus Wissen handlungsrelevante Entscheidungen ableiten kÃ¶nnen. Hier wird es praktisch â€“ und manchmal Ã¼berlebenswichtig.

    {{5}}
<section>

### Weisheit

    --{{5}}--
Weisheit ist angewandtes Wissen fÃ¼r Entscheidungen. Alle Informationen Ã¼ber den Krieger fÃ¼hren zu einer klaren Handlungsempfehlung: "Konflikt vermeiden!" In Datenbanken entspricht das den Business Intelligence Systemen, die aus Mustern Aktionen ableiten: "Kunde X hat 80% Abwanderungsrisiko â€“ sofort Retention-MaÃŸnahmen einleiten." Weisheit macht Daten actionable.

``` ascii
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âš ï¸  THREAT ASSESSMENT: MAXIMUM  âš ï¸     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Combat Experience:    [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 10/10â”‚
â”‚ Leadership Skills:    [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘â–‘]  8/10â”‚
â”‚ Survival Instinct:    [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 10/10â”‚
â”‚ Strategic Thinking:   [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‘]  9/10â”‚
â”‚ Recommendation:       AVOID CONFLICT    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

{{6}} "WÃ¼rde ich diesem Typen das Pferd stehlen?" â†’ {7}{__NEIN__}

{{8}} "WÃ¼rde ich ihn in meinem Team haben wollen?" â†’ {9}{__DEFINITIV JA__}

{{10}} "WÃ¼rde ich ihm widersprechen?" â†’ {11}{__Nur sehr hÃ¶flich__}

</section>

## DIKW Pyramide

    --{{0}}--
Jetzt konsolidieren wir unsere Erkenntnisse in der DIKW-Pyramide. Diese Hierarchie ist nicht nur akademische Theorie â€“ sie ist das Fundament fÃ¼r jede Datenbankarchitektur. Jede Ebene stellt andere Anforderungen an Speicherung, Verarbeitung und Zugriff. Verstehen Sie DIKW, verstehen Sie, warum verschiedene Datenbank-Paradigmen existieren.

    {{0}}
<section>

**DIKW** steht fÃ¼r **Data, Information, Knowledge, Wisdom** (Daten, Informationen, Wissen, Weisheit) und beschreibt eine Hierarchie der Verarbeitung und Bedeutung von Daten.

</section>

    --{{1}}--
Die Pyramide zeigt uns vier Stufen der WertschÃ¶pfung. Unten haben wir das Rohmaterial â€“ Daten. Jede Stufe nach oben wird wertvoller, aber auch komplexer zu verarbeiten. In Datenbanken entspricht jede Ebene verschiedenen Systemanforderungen.

    {{1}}
``` ascii
.-----------------------------------------------------------------------------.
|                   _                                                         |
|                  / \                                                        |
|                 / W \                  "4. __W__isdom (Weisheit)"           |
|                /_____\                                                      |
|               /       \                                                     |
|              /    K    \               "3. __K__nowledge (Wissen)"          |
|             /___________\                                                   |
|            /             \                                                  |
|           /       I       \            "2. __I__nformation (Informationen)" |
|          /_________________\                                                |
|         /                   \                                               |
|        /          D          \         "1. __D__ata (Daten)"                |
|       /_______________________\                                             |
|                                                                             |
'-----------------------------------------------------------------------------'
```

    --{{2}}--
Lassen Sie uns jede Ebene mit ihren Datenbank-Entsprechungen verstehen. Die Basis: Daten sind die rohen Feldwerte. Informationen fÃ¼gen Semantik hinzu. Wissen erkennt Muster durch Queries. Und Weisheit leitet Aktionen ab â€“ das ist Business Intelligence.

    {{2}}
<section>

**Die vier Ebenen in Datenbank-Kontext:**

- **[Daten](https://de.wikipedia.org/wiki/Daten):** Rohe Feldwerte ohne Kontext (`"42"`, `"Schmidt"`, `"2023-10-03"`)
- **[Information](https://de.wikipedia.org/wiki/Information):** Semantische Bedeutung (`"Alter: 42 Jahre"`, `"Nachname: Schmidt"`)  
- **[Wissen](https://de.wikipedia.org/wiki/Wissen):** Muster durch Queries (`"Kunden Ã¼ber 40 kaufen hÃ¤ufiger Produkt X"`)
- **[Weisheit](https://de.wikipedia.org/wiki/Weisheit):**

  Handlungsempfehlungen (`"Kunde Schmidt â†’ Produkt X empfehlen"`)

</section>

    --{{3}}--
Unser Indianer-Beispiel durchlÃ¤uft genau diese Stufen: Rohe Pixel werden zu kulturellen Codes, diese zu systematischem VerstÃ¤ndnis, und schlieÃŸlich zu der weisen Entscheidung: "Besser nicht Ã¤rgern!" Jede Datenbank-Anwendung macht dieselbe Reise.

## Datenorganisation â€“ Die Ewige Suche nach Ordnung

    --{{0}}--
Hier ist eine unbequeme Wahrheit: Jede Datenbank lÃ¶st ein Problem, das Menschen jahrhundertelang von Hand gemacht haben. Und oft haben sie es besser gemacht als wir heute glauben.

    {{1}}
<section>

    --{{1}}--
**1970 prÃ¤gte Edgar Codd, der Erfinder der relationalen Datenbanken, den folgenden Satz:**
__"The relational model provides a means of describing data with its natural structure only"__

![Codd Poesiealbum](../assets/img/codd-album-1970.jpg "Abb.: E. F. Codds Freundschaftsalbum-Eintrag 1970 â€“ Relationale Datenbank -- erstellt mit ChatGPT")

<!---
Prompt: Create a beautifully detailed academic friendship album (Poesiealbum) from 1970, photographed in an open state showing two facing pages in 16:9 format. The album has deep brown leather binding with gold embossed decorative borders. The left page shows elegant academic calligraphy reading "To the Future of Data Management" decorated with subtle geometric patterns and mathematical symbols. The right page displays a structured entry with clear fields: "Name: Dr. Edgar F. Codd", "Date: June 12, 1970", "Place: IBM Research, San Jose" followed by his famous handwritten quote in neat academic penmanship: "The relational model provides a means of describing data with its natural structure only - that is, without superimposing any additional structure for machine representation purposes. - E.F. Codd". Below this, in smaller script: "A relational model of data for large shared data banks". The pages are cream-colored with very light aging appropriate to 1970s paper. Include subtle pen-and-ink border decorations with clean, modernist geometric motifs reflecting the computational age. Background shows a 1970s academic desk with IBM typewriter, computer punch cards, and academic papers. Warm incandescent lighting suggests a university office. Photorealistic style with emphasis on authentic 1970s academic penmanship and period-appropriate details.
--->

    --{{3}}--
**Die Ironie?** Seine "revolutionÃ¤re" Idee war ein RÃ¼ckschritt zu dem, was Bibliothekare seit 100 Jahren mit Karteikarten machten!

    --{{3}}--
Und Ja, ein Poesiealbum ist tatsÃ¤chlich eine Art Datenbank â€“ mit EintrÃ¤gen, Attributen, einem impliziten Schema und IntegritÃ¤tsregeln. Es ist theoretisch und praktisch ein spezialisiertes und  handgefertigtes, physisches Datenbanksystem, das Menschen seit Generationen nutzen.

</section>

    --{{4}}--
Bevor wir uns in NoSQL, NewSQL und anderen Buzzwords verlieren, schauen wir zurÃ¼ck: Was haben Menschen frÃ¼her richtig gemacht? Welche Probleme haben sie elegant gelÃ¶st? Und wo sind sie gescheitert â€“ sodass wir Maschinen brauchten?

### Historische Beispiele fÃ¼r Datenorganisation ğŸŒ¾

    --{{0}}--
Hier beginnt eine faszinierende Entdeckungsreise: Jede moderne Datenbank lÃ¶st Probleme, die Menschen jahrhundertelang von Hand gemeistert haben. Und erstaunlicherweise haben unsere Vorfahren oft elegantere LÃ¶sungen gefunden, als wir heute glauben. Lassen Sie uns die DNA moderner Datenspeicherung in historischen Systemen aufspÃ¼ren.

    {{0}}
<section>

**Unsere Zeitreise durch 5000 Jahre Datenorganisation:**

> Jede "revolutionÃ¤re" Datentechnologie hat historische Wurzeln. Wir lernen nicht nur, **was** funktioniert â€“ sondern **warum** es schon immer funktionierte.

</section>

    --{{1}}--
Beginnen wir bei den AnfÃ¤ngen: Die alten Ã„gypter und Sumerer hatten bereits ein kritisches Problem erkannt â€“ wie dokumentiert man Mengen und Verteilungen so, dass Betrug schwierig wird und Nachvollziehbarkeit gewÃ¤hrleistet ist? Ihre Tontafeln und Papyri waren die ersten "Audit Trails" der Menschheitsgeschichte.

    {{1}}
<section>

### 1. FrÃ¼he Verwaltungslisten (3000 v.Chr. - 500 n.Chr.) ğŸ“œ

![Keilschrift Tafel](https://upload.wikimedia.org/wikipedia/commons/5/54/Clay_Tablet_-_Louvre_-_AO29562_%28cropped%29.jpg "Precuneiform table -AO 29562 (Louvre) â€” Photo: Poulpy / Zunkir, Wikimedia Commons, CC BY-SA 3.0")

    --{{2}}--
Diese frÃ¼hen Systeme verfolgten ein klares Ziel: verlÃ¤ssliche Mengennachweise und Verteilungskontrolle. Die Herausforderungen? Doppelte EintrÃ¤ge, mehrdeutige Interpretationen und fehlende Standardisierung untergruben das Vertrauen und machten Abgleiche extrem aufwendig.

      {{2}}
<div>

**Problem gelÃ¶st:** âœ… Dauerhafte Persistenz, âŒ Inkonsistenz-PrÃ¤vention

```ascii

ğŸº GETREIDESPEICHER BABYLON (ca. 2500 v.Chr.)

 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
 â”‚ DATUM: 3. MOND NISANNU                  â”‚
 â”‚ EMPFÃ„NGER: HAMMURABI-SOHN               â”‚
 â”‚ ----------------------------------------â”‚
 â”‚ MENGE: |||||||||| (10 MaÃŸ Gerste)       â”‚
 â”‚ KONTROLLE: ğ’Œ‘ğ’€€ğ’Œ‘ (Doppelt eingetragen) â”‚
 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Moderne DNA:** Append-Only Logs, Audit Trails

</div>

</section>

    --{{3}}--
Springen wir ins Mittelalter: Luca Pacioli revolutionierte 1494 das Rechnungswesen mit einem eleganten Trick â€“ jede Transaktion wird doppelt erfasst. Soll und Haben mÃ¼ssen sich ausgleichen, sonst stimmt etwas nicht. Das ist die Ur-Idee der Transaktions-IntegritÃ¤t!

    {{3}}
<section>

### 2. Doppelte BuchfÃ¼hrung (~1494) ğŸ“š

![Portrait Luca Pacioli](https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Pacioli.jpg/1229px-Pacioli.jpg "Portrait of Luca Pacioli (1445â€“1517) with a student, attrib. Jacopo deâ€™ Barbari â€” Wikimedia Commons, Public Domain.")

    --{{4}}--
Paciolis GenialitÃ¤t lag in der Invariante: Jede Buchung erzeugt einen ausgleichenden Gegeneintrag. Fehler zeigen sich sofort als Unbalancen. Dieses Prinzip ist das Fundament fÃ¼r moderne ACID-Transaktionen â€“ AtomizitÃ¤t durch systematische DualitÃ¤t.

    --{{4}}--
Im Beispiel sehen wir, wie jede Transaktion zwei Seiten hat â€“ Soll und Haben. Am Ende muss die Summe beider Seiten Ã¼bereinstimmen. Im ersten Eintrag wird Geld in die Kasse gelegt (Soll), im zweiten werden Waren gekauft (Haben). Danach werden gegen einen Kredit Waren eingekauft (Soll). Im letzten Eintrag wird ein Gewinn (Soll) aus der Kasse entnommen (Haben). Am Ende stimmen die Summen Ã¼berein â€“ die BÃ¼cher sind ausgeglichen.

      {{4}}
<div>

**Problem gelÃ¶st:** âœ… Transaktions-IntegritÃ¤t, âŒ Physische Skalierung

```ascii

    ğŸ“– HANDELSBUCH VENEDIG (1494)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚      SOLL       â”‚     HABEN       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ Kassa    +100 â‚¤ â”‚ Waren    -100 â‚¤ â”‚
â”‚ Waren    +200 â‚¤ â”‚ Kredit   -200 â‚¤ â”‚
â”‚ Gewinn   +50 â‚¤  â”‚ Kassa    -50 â‚¤  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SUMME:    350 â‚¤ â”‚ SUMME:    350 â‚¤ â”‚ âœ“
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Moderne DNA:** ACID-Transaktionen, Two-Phase Commit

</div>

</section>

    --{{5}}--
Die Seefahrt brachte eine weitere Innovation: das Logbuch. Jeder Eintrag ist zeitgestempelt, nichts wird gelÃ¶scht, alles wird nacheinander aufgeschrieben. Bei SchiffsunglÃ¼cken oder Rechtsstreitigkeiten war die lÃ¼ckenlose Chronologie Ã¼berlebenswichtig. Das ist das Ur-Prinzip des Write-Ahead Logs!

    {{5}}
<section>

### 3. SchiffslogbÃ¼cher & Navigationsjournale âš“

![Schiffslogbuch](https://upload.wikimedia.org/wikipedia/commons/thumb/2/26/LogBook2.png/1280px-LogBook2.png "Autor: Belleami / Cythera, Public Domain, Wikimedia Commons")

    --{{6}}--
SchiffslogbÃ¼cher etablierten das Append-Only Prinzip: Kurs, Wetter und Ereignisse werden chronologisch festgehalten â€“ niemals Ã¼berschrieben, niemals gelÃ¶scht. Die Herausforderung? Uneinheitliche Formate und schwierige Querverweise machten Analysen mÃ¼hsam.

      {{6}}
<div>

**Problem gelÃ¶st:** âœ… Append-Only Durability, âŒ Strukturierte Abfragen

```ascii

     ğŸ§­ LOGBUCH HMS BEAGLE (1831-1836)

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Tag 847: 15Â° S, 47Â° W | Wind: SO 4 bft  â”‚
â”‚ Darwin sammelt Finken | Wasser: 300 Ltr â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Tag 848: 16Â° S, 48Â° W | Wind: O 2 bft   â”‚
â”‚ Sturm voraus sichtbar | Segel gerefft   â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ Tag 849: POSITION UNBEKANNT | Kompass   â”‚
â”‚ defekt | Darwin seekrank | NOTLAGE!     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Moderne DNA:** Write-Ahead Logs, Event Sourcing

</div>

</section>

    --{{7}}--
Ende des 19. Jahrhunderts perfektionierten Bibliothekare ein System, das heute noch beeindruckt: Katalogkarten. FÃ¼r jedes Buch mehrere Zugriffspfade â€“ nach Autor, Titel, Thema. Das ist die Erfindung der SekundÃ¤rindizes! Millionen von BÃ¼chern, gefunden in Sekunden.

    {{7}}
<section>

### 4. Bibliotheks-Katalogkarten (Dewey Decimal, 1876) ğŸ“š

      {{8}}
<div>

![Card catalog Yale](https://upload.wikimedia.org/wikipedia/commons/a/a6/Yale_card_catalog.jpg "Kartei-System der Yale University Library")
![Schlagwortkatalog](https://upload.wikimedia.org/wikipedia/commons/thumb/7/7e/Schlagwortkatalog.jpg/1211px-Schlagwortkatalog.jpg "*Schlagwortkatalog* â€” Foto: Bernhard/Wikimedia Commons, Lizenz: CC BY-SA 4.0 ([commons.wikimedia.org](https://commons.wikimedia.org/wiki/File:Schlagwortkatalog.jpg))")
![Dewey Decimal System](https://upload.wikimedia.org/wikipedia/commons/9/91/B%C3%BChrer_Saager_Die_Welt-Registratur._Das_Melvil-Deweysche_Dezimal-System_%E2%80%94_Beispiel_f%C3%BCr_Systematik_Astronomie.jpg "Dewey Decimal Classification System - Astronomie")

</div>

    --{{8}}--
Melvil Dewey und seine Zeitgenossen lÃ¶sten das Indexierungs-Problem elegant: Mehrere Zugriffspfade auf dieselben Daten, systematische Kategorisierung, und O(log n) Suchzeit durch alphabetische Ordnung. Probleme entstanden durch physische Fragmentierung und Redundanz-Management â€“ aber das Grundprinzip war brillant.

      {{9}}
<div>

**Problem gelÃ¶st:** âœ… SekundÃ¤re Zugriffspfade, âŒ Konsistenz bei Updates

```ascii
  ğŸ—‚ï¸  DEWEY DECIMAL SYSTEM - INDEX DESIGN
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ HAUPTKATALOG (nach Standort)            â”‚
â”‚ 510.123 â†’ "Mathematik: Algebra Bd.3"    â”‚
â”‚                                         â”‚
â”‚ AUTORENKATALOG (nach Nachname)          â”‚
â”‚ "Einstein" â†’ [510.543, 523.877, ...]    â”‚
â”‚                                         â”‚
â”‚ SCHLAGWORTKATALOG (nach Thema)          â”‚
â”‚ "RelativitÃ¤t" â†’ [523.877, 510.543]      â”‚
â”‚                                         â”‚
â”‚ PROBLEM: 3x Redundanz, manueller Sync!  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Moderne DNA:** B-Tree Indizes, Multi-Column Indexing

</div>

</section>

    --{{10}}--
1890 revolutionierte Herman Hollerith die Datenverarbeitung: Standardisierte Lochkarten fÃ¼r den US-Zensus. Erstmals konnten Millionen von DatensÃ¤tzen maschinell ausgewertet werden. Der Preis? Ein starres Schema â€“ jede Ã„nderung bedeutete neue Hardware-Konfiguration.

    {{10}}
<section>

### 5. Hollerith-Lochkarten (US Census 1890) ğŸ•³ï¸

![Hollerith Lochkarte](https://upload.wikimedia.org/wikipedia/commons/e/ea/Hollerith_Punched_Card.jpg "*Punchkarte fÃ¼r Herman Holleriths elektrische Sortier- und Tabuliermaschine, ca. 1895* â€” Public Domain (Library of Congress). Wikimedia Commons.")

    --{{11}}--
Holleriths Innovation war die physische Standardisierung: Jede Karte hatte exakt dieselbe Struktur, jede Position eine definierte Bedeutung. Das ermÃ¶glichte erstmals automatisierte Statistiken Ã¼ber Millionen Menschen. Aber Schema-Ã„nderungen bedeuteten Hardware-Umbau â€“ FlexibilitÃ¤t war unmÃ¶glich.

      {{11}}
<div>

**Problem gelÃ¶st:** âœ… Maschinelle Auswertung, âŒ Schema-FlexibilitÃ¤t

```ascii
     ğŸ•³ï¸  HOLLERITH CENSUS CARD (1890)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Col 1-2: AGE     [â—â—]   = 42 Jahre      â”‚
â”‚ Col 3:   SEX     [â—]    = Male          â”‚
â”‚ Col 4-5: STATE   [â—â—]   = New York      â”‚
â”‚ Col 6:   MARRIED [â—]    = Yes           â”‚
â”‚ Col 7-8: OCCUP   [â—â—]   = Farmer        â”‚
â”‚ Col 9:   LITERATE[â—]    = Can Read      â”‚
â”‚ Col 10:  CITIZEN [â—]    = Native Born   â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ â”‚
â”‚ 80 Spalten, fixes Format, Maschine liestâ”‚
â”‚ 500 Karten/Minute! (vs. Jahre manuell)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Moderne DNA:** Schema-Enforcer, Column-Based Storage

</div>

</section>

    --{{12}}--
Und damit schlieÃŸt sich der Kreis zu unserem Eingangsbild: Edgar Codds "revolutionÃ¤re" relationale Theorie war im Grunde eine RÃ¼ckkehr zu den Katalogkarten-Prinzipien â€“ aber mit mathematischer PrÃ¤zision und maschineller FlexibilitÃ¤t. Die Ironie der Informatikgeschichte!

    {{12}}
<section>

### 6. Der Kreis schlieÃŸt sich: Codd 1970 â†’ Heute â™»ï¸

    --{{13}}--
Schauen Sie zurÃ¼ck auf unsere Zeitreise: Jedes "neue" Datenbankkonzept hat historische Wurzeln. Append-Only Logs? SchiffstagebÃ¼cher. ACID-Transaktionen? Doppelte BuchfÃ¼hrung. SekundÃ¤rindizes? Katalogkarten. Die Innovation liegt nicht in der Erfindung neuer Prinzipien â€“ sondern in deren maschineller Perfektionierung.

![Codd Poesiealbum](../assets/img/codd-album-1970.jpg "Abb.: E. F. Codds Freundschaftsalbum-Eintrag 1970 â€“ Relationale Datenbank -- erstellt mit ChatGPT")

</section>

## Datenformate im Vergleich: CSV, JSON, XML & Co.

    --{{0}}--
Wir haben die historischen Grundlagen gelegt â€“ jetzt wird es praktisch! In der nÃ¤chsten Session nehmen wir uns reale Datenformate vor und sehen, wo sie uns im Stich lassen. CSV, JSON, XML â€“ jedes Format hat seine Berechtigung, aber auch seine TÃ¼cken.

![](https://media3.giphy.com/media/v1.Y2lkPTc5MGI3NjExMzc2Y2gxMjc5ZWJlaGp2bjE4bTNqNmV0eHg4MW5ueGo2NzU5bWU3NCZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/xT9C25UNTwfZuk85WP/giphy.gif)<!-- style="width: 100%" -->


### CSV - Das trojanische Pferd der Datenformate ğŸ´

    --{{0}}--
CSV - Comma Separated Values - ist das Schweizer Taschenmesser der Datenwelt. Jeder kennt es, jeder nutzt es, und jeder unterschÃ¤tzt seine TÃ¼cken. Als praxisorientierter Architekt sage ich Ihnen: CSV ist gleichzeitig das nÃ¼tzlichste und gefÃ¤hrlichste Format, das Sie je verwenden werden.

    {{0}}
<section>

### Was ist CSV eigentlich?

CSV steht fÃ¼r **Comma Separated Values** - eine scheinbar simple Textdatei, in der DatensÃ¤tze zeilenweise und Felder durch Kommas getrennt gespeichert werden.

> **Die Ironie:** Ein "Standard" ohne echte Standardisierung - RFC 4180 kam erst 2005, nachdem CSV bereits 20 Jahre wild gewachsen war!

</section>

    --{{1}}--
Schauen wir uns die Anatomie einer CSV-Datei an. Auf den ersten Blick wirkt es harmlos - Zeilen, Kommas, fertig. Aber der Teufel steckt im Detail: Was passiert, wenn ein Feld selbst ein Komma enthÃ¤lt? Wie codiere ich AnfÃ¼hrungszeichen? Welche Zeichen sind Zeilenenden?

    {{1}}
<section>

### Die Anatomie einer CSV-Datei

<script run-once modify="false" style="display: block">
fetch("../assets/dat/titanic.csv")
  .then(response => response.text())
  .then(data => {
    send.lia("LIASCRIPT: ````csv\n" + data.split("\n").slice(0,16).join("\n") + "\n...\n````");
  }).catch(error => {
    send.lia('Error fetching the file:', error);
  });
"LIA: wait"
</script>

**Grundregeln (die niemand einheitlich befolgt):**

- Erste Zeile = Header (meist, aber nicht immer)
- Komma = Feldtrenner (auÃŸer es ist Semikolon, Tab, oder Pipe)
- AnfÃ¼hrungszeichen fÃ¼r Felder mit Sonderzeichen (wenn Ã¼berhaupt)
- Zeilenende = Datensatz-Ende (CR, LF, oder CRLF?)

</section>

    --{{2}}--
Hier beginnt das CSV-Drama! Jeder implementiert es anders. Excel nutzt regional unterschiedliche Trennzeichen - in Deutschland Semikolon statt Komma, weil Komma als Dezimaltrennzeichen dient. FranzÃ¶sische Systeme nutzen andere Kodierungen. Und dann gibt es noch die Escape-HÃ¶lle: Wie schreibt man AnfÃ¼hrungszeichen in ein angefÃ¼hrtes Feld?

    {{2}}
<section>

### ğŸš¨ Die CSV-HÃ¶lle: Wilde Varianten

```csv     ğŸŒ INTERNATIONALE CSV-VERWIRRUNG
US-Style,      "Smith,John",   42,50000
German-Style,  "Smith,John";   42;50000
French-Style,  "Smith,John";   42;50000
Unix-Style,     Smith\,John,   42,50000
Excel-Export,  "Smith, John",  42,50000
Database-Dump, 'Smith, John',  42,50000
```

**Die vier Hauptprobleme:**

1. **Trennzeichen-Chaos:** `,` vs `;` vs `\t` vs `|`
2. **Escape-HÃ¶lle:** Wie kodiere ich `"` in `"Feld"`?
3. **Encoding-Wirrwarr:** UTF-8 vs Latin-1 vs Windows-1252
4. **Implizite Typen:** Ist `"42"` Text oder Zahl?

</section>

    --{{3}}--
Lassen Sie uns praktisch werden! Hier ist ein echter CSV-Alptraum aus der Praxis. Schauen Sie genau hin - kÃ¶nnen Sie alle Probleme erkennen? Inkonsistente AnfÃ¼hrungszeichen, mixed Encodings, verschiedene Datumsformate, und sogar eingebettete Zeilenwechsel. Das ist leider RealitÃ¤t, nicht Ãœbertreibung.

    {{3}}
<section>

### ğŸ’€ CSV-Alptraum aus der Praxis (Titanic-Export vom Legacy-System)

```csv
PassengerId,Survived,Pclass,Name,Sex,Age,SibSp,Parch,Ticket,Fare,Cabin,Embarked
1,0,3,"Braund, Mr. Owen Harris",male,1912-04-15,1,0,A/5 21171,7.25,,S
2,1,1,Cumings, Mrs. John Bradley (Florence Briggs Thayer),female,38,1,0,PC 17599,71.2833,C85,Cherbourg
3,1,3,"Heikkinen, Miss. Laina",female,26.0,0,0,STON/O2. 3101282,7.925,,Southampton
"4",1,1,"Futrelle, Mrs. Jacques Heath (Lily May Peel)
Notiz: Ãœberlebte in Rettungsboot 9",female,35,1,0,113803,53,1â‚¬,C123,S
5,0,3,"Allen, Mr. William Henry",mÃ¢le,35,0,0,373450,8.05,NULL,S
```

    {{4}}
<div>
**Probleme identifiziert (alle in 5 Zeilen!):**

1. **Inkonsistente Datumsformate:** `1912-04-15` (ISO) vs. `38` (Alter) vs. `26.0` (Float) â€“ Age-Spalte gemischt!
2. **Inkonsistente Quotes:** Zeile 2 fehlt Opening-Quote bei Name â†’ Parser-Chaos
3. **Mixed Encoding:** `mÃ¢le` (French UTF-8) statt `male` â†’ Latin-1/UTF-8 Konflikt
4. **Multiline Fields:** Zeile 4 hat Zeilenwechsel in Name-Feld â†’ "Notiz: Ãœberlebte..."
5. **Quoted Numbers:** `"4"` als PassengerId â†’ String statt Integer
6. **Type Confusion:** `7.25` vs `53,1â‚¬` vs `53` â€“ verschiedene WÃ¤hrungs-/Dezimalnotationen
7. **Mixed Value Semantics:** `` (leer) vs `NULL` vs fehlende Spalte â€“ drei Arten von "missing"
8. **Inconsistent Categories:** `S` vs `Southampton` vs `Cherbourg` â€“ mal Code, mal Volltext

</div>

      --{{4}}--
**Real-World Impact:** Ein einziger falsch escapeter Zeilenwechsel kann eine komplette Datenimport-Pipeline zum Absturz bringen!

</section>

    --{{5}}--
Warum wird CSV trotz all dieser Probleme so viel verwendet? Weil es funktioniert - meistens. Es ist das kleinste gemeinsame Vielfache aller Systeme. Jede Programmiersprache kann es lesen, jede Datenbank kann es importieren, jeder Mensch kann es verstehen. Es ist der Duct-Tape der Datenwelt.

    {{5}}
<section>

### âœ… Warum CSV trotzdem Ã¼berlebt

**Die StÃ¤rken:**

- **Universal lesbar:** Von Excel bis Python, von MySQL bis Notepad
- **Menschenlesbar:** Man sieht sofort, was drin steht  
- **Kompakt:** Wenig Overhead, hohe Datendichte
- **Stream-fÃ¤hig:** Kann zeilenweise verarbeitet werden
- **Git-freundlich:** Textbasiert, diff-bar, mergeable

**Die SchwÃ¤chen:**

- **Schemalos:** Keine Typdefinitionen, keine Validierung
- **FehleranfÃ¤llig:** Silent Failures bei Parsing-Problemen
- **Begrenzt:** Keine Verschachtelung, keine Metadaten
- **Inkonsistent:** Jeder interpretiert den "Standard" anders

</section>

    --{{6}}--
Hier ist Ihr Praxis-Guide fÃ¼r den Umgang mit CSV. Diese Regeln haben mir in 15 Jahren Datenarchitektur viel Ã„rger erspart. Definieren Sie IMMER das Schema explizit, nutzen Sie UTF-8 BOM fÃ¼r Excel-KompatibilitÃ¤t, und testen Sie mit echten Daten - nicht nur mit Ihren sauberen TestdatensÃ¤tzen.

    {{6}}
<section>

### ğŸ› ï¸ CSV-Survival-Guide fÃ¼r Profis

**Beim CSV-Import (Sie kriegen Daten rein):**

``` python @PyScript.repl
import pyodide.http
import pandas as pd
from io import StringIO

async def fetch_data(url):
    response = await pyodide.http.pyfetch(url)  # Daten abrufen
    csv_data = await response.string()  # Inhalt als String laden
    df = pd.read_csv(StringIO(csv_data))  # In DataFrame umwandeln
    return df

# Funktion direkt aufrufen mit `await` (NICHT `asyncio.run()`)
url = "https://raw.githubusercontent.com/andre-dietrich/Datenbankensysteme-Vorlesung/refs/heads/main/assets/dat/titanic.csv"
Titanic = await fetch_data(url)

# Ausgabe
Titanic
```

---


```python @PyScript.repl
import matplotlib.pyplot as plt

# Absolute HÃ¤ufigkeit der Ãœberlebenden und Nicht-Ãœberlebenden berechnen
absolute_counts = Titanic.groupby(["Pclass", "Sex"])["Survived"].value_counts().unstack()

# Visualisierung der absoluten HÃ¤ufigkeiten
absolute_counts.plot(kind="bar", stacked=True, figsize=(10,6), edgecolor="black")
plt.title("Absolute HÃ¤ufigkeit der Ãœberlebenden nach Passagierklasse und Geschlecht")
plt.xlabel("Passagierklasse und Geschlecht")
plt.ylabel("Anzahl der Passagiere")
plt.xticks(rotation=0)
plt.legend(["Nicht Ãœberlebt", "Ãœberlebt"], title="Status")
plt.grid(axis="y", linestyle="--", alpha=0.7)
plt.show()
plt
```

---

``` r
library(ggplot2)
library(dplyr)

# CSV-Datei einlesen
df <- read.csv("https://raw.githubusercontent.com/andre-dietrich/Datenbankensysteme-Vorlesung/refs/heads/main/assets/dat/titanic.csv")

# Alter bereinigen (NA-Werte entfernen)
df <- df %>% filter(!is.na(Age))

# Ãœberlebenswahrscheinlichkeit nach Geschlecht und Alter (inkl. MÃ¤nner)
women_children_men <- df %>% 
  mutate(Category = case_when(
    Sex == "female" & Age < 18 ~ "Female Child",
    Sex == "female" & Age >= 18 ~ "Female Adult",
    Sex == "male" & Age < 18 ~ "Male Child",
    Sex == "male" & Age >= 18 ~ "Male Adult"
  )) %>%
  group_by(Category) %>% 
  summarise(SurvivalRate = mean(Survived), .groups = 'drop')

# PNG-Datei fÃ¼r Analyse speichern
png("women_children_men_survival.png", width = 800, height = 400)

ggplot(women_children_men, aes(x = Category, y = SurvivalRate, fill = Category)) +
  geom_bar(stat = "identity", position = "dodge") +
  ggtitle("Ãœberlebenswahrscheinlichkeit von Frauen, MÃ¤nnern und Kindern") +
  xlab("Kategorie") +
  ylab("Ãœberlebensrate") +
  scale_fill_manual(values = c("blue", "red", "green", "purple"), name = "Kategorie") +
  theme_minimal()

dev.off()
```
@LIA.r


</section>


    --{{8}}--
Zum Abschluss: CSV ist wie ein Schraubendreher - fÃ¼r manche Aufgaben perfekt, fÃ¼r andere vÃ¶llig ungeeignet. Nutzen Sie es fÃ¼r Datenexporte, ETL-Zwischenschritte und schnelle Analysen. Aber bauen Sie nie eine Anwendung darauf auf. In der nÃ¤chsten Session sehen wir, wie JSON versucht, CSVs SchwÃ¤chen zu beheben.

    {{8}}
<section>

### ğŸ¯ Wann CSV verwenden - Wann nicht

**âœ… CSV ist perfekt fÃ¼r:**

- **Datenexport** aus Datenbanken fÃ¼r Analysen
- **ETL-Pipelines** als Zwischenformat  
- **Reporting** fÃ¼r Business-User (Excel-Import)
- **Data Science** fÃ¼r schnelle explorative Analysen
- **Logs** mit strukturierten Events

**âŒ CSV ist schlecht fÃ¼r:**

- **Produktive Datenhaltung** (keine IntegritÃ¤t)
- **APIs** (keine Typisierung, kein Schema)
- **Hierarchische Daten** (keine Verschachtelung)
- **Multi-User Szenarien** (Concurrency-Probleme)
- **Komplexe Queries** (keine JOIN-UnterstÃ¼tzung)

> **Professor Freinets Regel:** CSV fÃ¼r Transport, nie fÃ¼r Storage!

</section>



### XML - Als Ordnung zur BÃ¼rokratie wurde ğŸ“œ

    --{{0}}--
XML - Extensible Markup Language - ist das formale GegenstÃ¼ck zu CSV. Wo CSV zu locker ist, schoss XML Ã¼ber das Ziel hinaus. Als praxisorientierter Architekt sage ich Ihnen: XML ist wie ein Ã¼bervorsichtiger Anwalt - jedes Detail wird geprÃ¼ft, jede Regel befolgt, aber am Ende dauert alles dreimal so lange.

__Was ist XML eigentlich?__

XML steht fÃ¼r **Extensible Markup Language** - ein textbasiertes Format fÃ¼r **selbstbeschreibende, hierarchische Dokumente** mit strenger Validierung.

> **Die Mission:** Ordnung schaffen wo CSV Chaos hinterlieÃŸ - mit formalen Schemas, Namespaces und Validierung.
>
> **Das Resultat:** Der bÃ¼rokratische Overkill - mehr Zeilen Schema als Daten, mehr Parser-Overhead als Nutzen.


#### Die Anatomie einer XML-Datei

    --{{0}}--
Schauen wir uns die Anatomie von XML an. Auf den ersten Blick sieht es aus wie HTML - Tags, Attribute, Hierarchie. Aber der Unterschied ist fundamental: HTML ist nachsichtig ("best effort parsing"), XML ist streng ("well-formed or fail"). Ein einziges fehlendes Closing-Tag und der Parser verweigert die Arbeit.


```xml
<?xml version="1.0" encoding="UTF-8"?>
<library>
  <book isbn="978-0-13-110362-7">
    <title>The C Programming Language</title>
    <authors>
      <author>Brian Kernighan</author>
      <author>Dennis Ritchie</author>
    </authors>
    <year>1978</year>
    <price currency="USD">42.50</price>
  </book>
  <book isbn="978-0-13-468599-1">
    <title>Structure and Interpretation of Computer Programs</title>
    <authors>
      <author>Harold Abelson</author>
      <author>Gerald Jay Sussman</author>
    </authors>
    <year>1985</year>
    <price currency="USD">65.00</price>
  </book>
</library>
```

**Grundelemente:**

- **Prolog:** `<?xml version="1.0" encoding="UTF-8"?>` (optional, aber empfohlen)
- **Root-Element:** Genau ein umschlieÃŸendes Element (hier `<library>`)
- **Tags:** Ã–ffnend und schlieÃŸend, case-sensitive: `<book>...</book>`
- **Attribute:** Key-Value Paare in Ã¶ffnenden Tags: `isbn="..."`
- **Hierarchie:** Beliebig tiefe Verschachtelung mÃ¶glich


    {{1}}
<section>

### Well-formed vs. Valid - Der Unterschied

    --{{1}}--
XML unterscheidet zwei QualitÃ¤tsstufen: "well-formed" und "valid". Well-formed bedeutet syntaktisch korrekt - alle Tags geschlossen, keine ungÃ¼ltigen Zeichen, ein Root-Element. Valid bedeutet zusÃ¤tzlich: entspricht einem Schema. Und hier beginnt die XML-HÃ¶lle.

**Well-formed** = Syntaktisch korrekt

```xml
<!-- âœ… Well-formed -->
<person>
  <name>John</name>
  <age>42</age>
</person>

<!-- âŒ NOT well-formed: Missing closing tag -->
<person>
  <name>John</name>
  <age>42
</person>

<!-- âŒ NOT well-formed: Case mismatch -->
<Person>
  <name>John</name>
</person>
```

**Valid** = Entspricht einem Schema (DTD, XSD, RELAX NG)

```xml
<!-- Schema sagt: "age" muss Integer sein -->
<!-- âœ… Valid -->
<person>
  <name>John</name>
  <age>42</age>
</person>

<!-- âŒ NOT valid: age ist kein Integer -->
<person>
  <name>John</name>
  <age>forty-two</age>
</person>
```

</section>


#### ğŸ›ï¸ Das Schema-Ã–kosystem - Drei Wege zur Validierung


    --{{3}}--
Jetzt kommen wir zum XML-Ã–kosystem der Schema-Sprachen. Es gibt drei HauptansÃ¤tze: DTD aus den 90ern - einfach aber limitiert. XSD, der W3C-Standard - mÃ¤chtig aber monstrÃ¶s verbose. Und RELAX NG - elegant aber kaum verbreitet. Das Problem? FÃ¼r jede dieser Sprachen brauchen Sie ein eigenes Buch.


```ascii
ğŸ“š XML SCHEMA EVOLUTION
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ DTD (1990s)     - Simple, limited       â”‚
â”‚ XSD (2001)      - Powerful, VERBOSE     â”‚
â”‚ RELAX NG (2003) - Elegant, unpopular    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**DTD (Document Type Definition):**

```dtd
<!DOCTYPE library [
  <!ELEMENT library (book+)>
  <!ELEMENT book (title, authors, year, price)>
  <!ELEMENT title (#PCDATA)>
  <!ELEMENT authors (author+)>
  <!ELEMENT author (#PCDATA)>
  <!ELEMENT year (#PCDATA)>
  <!ELEMENT price (#PCDATA)>
  <!ATTLIST book isbn CDATA #REQUIRED>
  <!ATTLIST price currency CDATA #IMPLIED>
]>
```

**XSD (XML Schema Definition):**


```
<xs:schema xmlns:xs="http://www.w3.org/2001/XMLSchema">
  <xs:element name="library">
    <xs:complexType>
      <xs:sequence>
        <xs:element name="book" maxOccurs="unbounded">
          <xs:complexType>
            <xs:sequence>
              <xs:element name="title" type="xs:string"></xs:element>
              <xs:element name="authors">
                <xs:complexType>
                  <xs:sequence>
                    <xs:element name="author" type="xs:string" maxOccurs="unbounded"></xs:element>
                  </xs:sequence>
                </xs:complexType>
              </xs:element>
              <xs:element name="year" type="xs:integer"></xs:element>
              <xs:element name="price">
                <xs:complexType>
                  <xs:simpleContent>
                    <xs:extension base="xs:decimal">
                      <xs:attribute name="currency" type="xs:string"></xs:attribute>
                    </xs:extension>
                  </xs:simpleContent>
                </xs:complexType>
              </xs:element>
            </xs:sequence>
            <xs:attribute name="isbn" type="xs:string" use="required"></xs:attribute>
          </xs:complexType>
        </xs:element>
      </xs:sequence>
    </xs:complexType>
  </xs:element>
</xs:schema>
```

**Das Paradox:** 40 Zeilen Schema fÃ¼r 12 Zeilen Daten! ğŸ¤¯



    --{{4}}--
Lassen Sie uns das Kernproblem von XML visualisieren: Verbosity. Jede Information wird mehrfach kodiert - im Ã¶ffnenden Tag, im schlieÃŸenden Tag, und eventuell nochmal im Schema. Das ist wie ein Brief, bei dem Sie auf jedem Umschlag dreimal Ihre Adresse schreiben mÃ¼ssen.

    {{4}}
<section>

### ğŸ’€ Der Verbosity-Alptraum - XML vs. Alternativen

```
ğŸ“Š GLEICHE PERSON - VERSCHIEDENE FORMATE
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CSV (30 Bytes):                         â”‚
â”‚ John Smith,42,Engineer,New York         â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ JSON (85 Bytes):                        â”‚
â”‚ {                                       â”‚
â”‚   "name": "John Smith",                 â”‚
â”‚   "age": 42,                            â”‚
â”‚   "job": "Engineer",                    â”‚
â”‚   "city": "New York"                    â”‚
â”‚ }                                       â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ XML (187 Bytes):                        â”‚
â”‚ <?xml version="1.0"?>                   â”‚
â”‚ <person>                                â”‚
â”‚   <name>John Smith</name>               â”‚
â”‚   <age>42</age>                         â”‚
â”‚   <job>Engineer</job>                   â”‚
â”‚   <city>New York</city>                 â”‚
â”‚ </person>                               â”‚
â”‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  â”‚
â”‚ Overhead: CSV 1x | JSON 2.8x | XML 6.2xâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

      {{5}}
<div>

**Real-World Impact:**

- **Bandbreite:** 6x mehr Datenvolumen als CSV
- **Parsing:** 10-50x langsamer als JSON (je nach Parser)
- **Lesbarkeit:** Menschen ertrinken in Closing-Tags
- **Wartung:** Schema-Ã„nderungen sind AlbtrÃ¤ume

> **Die Ironie:** XML sollte "human-readable" sein, aber niemand liest gerne 187 Bytes statt 30.

</div>

</section>

#### ğŸ” XPath & XQuery - Die mÃ¤chtigen Query-Sprachen


    --{{6}}--
Aber XML hat auch StÃ¤rken! Die Query-Sprachen XPath und XQuery sind extrem mÃ¤chtig. Mit XPath kÃ¶nnen Sie komplexe Pfade durch XML-BÃ¤ume navigieren - weit Ã¼ber das hinaus, was CSV je kÃ¶nnte. XQuery ist sogar Turing-vollstÃ¤ndig! Das Problem: Die Lernkurve ist steil und die Tools sind kompliziert.



https://learn.microsoft.com/en-us/previous-versions/windows/desktop/ms762271(v=vs.85)

**ğŸ¯ XPath Live-Demo: Buchkatalog abfragen**

Probieren Sie verschiedene XPath-Queries aus:

https://developer.mozilla.org/en-US/docs/Web/XML/XPath/Guides/Introduction_to_using_XPath_in_JavaScript

``` js
const xmlDoc = new DOMParser().parseFromString(books, 'text/xml');

// ğŸ” WÃ¤hlen Sie eine Query aus oder schreiben Sie eigene:

// Query 1: Alle Computer-BÃ¼cher
const query = '//book[genre="Computer"]/title/text()';

// Query 2: BÃ¼cher teurer als 10$
// const query = '//book[price > 10]/title/text()';

// Query 3: Alle Fantasy-BÃ¼cher von Eva Corets
// const query = '//book[author="Corets, Eva" and genre="Fantasy"]/title/text()';

// Query 4: GÃ¼nstigstes Buch (Titel)
// const query = '//book[price = min(//book/price)]/title/text()';

// Query 5: Durchschnittspreis aller BÃ¼cher
// const query = 'sum(//book/price) div count(//book)';

// Query 6: BÃ¼cher aus dem Jahr 2001
// const query = '//book[starts-with(publish_date, "2001")]/title/text()';

// Query 7: Alle Genres (mit Duplikaten)
// const query = '//book/genre/text()';

// âœ… Query ausfÃ¼hren
const resultType = typeof query === 'string' && 
                   (query.includes('sum(') || query.includes('count(') || 
                    query.includes('avg(') || query.includes('div'))
    ? XPathResult.NUMBER_TYPE
    : XPathResult.ORDERED_NODE_SNAPSHOT_TYPE;

const result = xmlDoc.evaluate(
    query,
    xmlDoc.documentElement,
    null,
    resultType,
    null
);

// ğŸ“Š Ergebnis formatieren
let output;
if (resultType === XPathResult.NUMBER_TYPE) {
    output = `ğŸ’° Ergebnis: ${result.numberValue.toFixed(2)}`;
} else {
    const items = [];
    for (let i = 0; i < result.snapshotLength; i++) {
        items.push(`${i + 1}. ${result.snapshotItem(i).textContent}`);
    }
    output = items.length > 0 
        ? `ğŸ“š Gefunden: ${items.length} Ergebnisse\n\n${items.join('\n')}`
        : 'âŒ Keine Ergebnisse gefunden';
}

output;
```
``` xml   Books.xml
<catalog>
   <book id="bk101">
      <author>Gambardella, Matthew</author>
      <title>XML Developer's Guide</title>
      <genre>Computer</genre>
      <price>44.95</price>
      <publish_date>2000-10-01</publish_date>
      <description>An in-depth look at creating applications 
      with XML.</description>
   </book>
   <book id="bk102">
      <author>Ralls, Kim</author>
      <title>Midnight Rain</title>
      <genre>Fantasy</genre>
      <price>5.95</price>
      <publish_date>2000-12-16</publish_date>
      <description>A former architect battles corporate zombies, 
      an evil sorceress, and her own childhood to become queen 
      of the world.</description>
   </book>
   <book id="bk103">
      <author>Corets, Eva</author>
      <title>Maeve Ascendant</title>
      <genre>Fantasy</genre>
      <price>5.95</price>
      <publish_date>2000-11-17</publish_date>
      <description>After the collapse of a nanotechnology 
      society in England, the young survivors lay the 
      foundation for a new society.</description>
   </book>
   <book id="bk104">
      <author>Corets, Eva</author>
      <title>Oberon's Legacy</title>
      <genre>Fantasy</genre>
      <price>5.95</price>
      <publish_date>2001-03-10</publish_date>
      <description>In post-apocalypse England, the mysterious 
      agent known only as Oberon helps to create a new life 
      for the inhabitants of London. Sequel to Maeve 
      Ascendant.</description>
   </book>
   <book id="bk105">
      <author>Corets, Eva</author>
      <title>The Sundered Grail</title>
      <genre>Fantasy</genre>
      <price>5.95</price>
      <publish_date>2001-09-10</publish_date>
      <description>The two daughters of Maeve, half-sisters, 
      battle one another for control of England. Sequel to 
      Oberon's Legacy.</description>
   </book>
   <book id="bk106">
      <author>Randall, Cynthia</author>
      <title>Lover Birds</title>
      <genre>Romance</genre>
      <price>4.95</price>
      <publish_date>2000-09-02</publish_date>
      <description>When Carla meets Paul at an ornithology 
      conference, tempers fly as feathers get ruffled.</description>
   </book>
   <book id="bk107">
      <author>Thurman, Paula</author>
      <title>Splish Splash</title>
      <genre>Romance</genre>
      <price>4.95</price>
      <publish_date>2000-11-02</publish_date>
      <description>A deep sea diver finds true love twenty 
      thousand leagues beneath the sea.</description>
   </book>
   <book id="bk108">
      <author>Knorr, Stefan</author>
      <title>Creepy Crawlies</title>
      <genre>Horror</genre>
      <price>4.95</price>
      <publish_date>2000-12-06</publish_date>
      <description>An anthology of horror stories about roaches,
      centipedes, scorpions  and other insects.</description>
   </book>
   <book id="bk109">
      <author>Kress, Peter</author>
      <title>Paradox Lost</title>
      <genre>Science Fiction</genre>
      <price>6.95</price>
      <publish_date>2000-11-02</publish_date>
      <description>After an inadvertant trip through a Heisenberg
      Uncertainty Device, James Salway discovers the problems 
      of being quantum.</description>
   </book>
   <book id="bk110">
      <author>O'Brien, Tim</author>
      <title>Microsoft .NET: The Programming Bible</title>
      <genre>Computer</genre>
      <price>36.95</price>
      <publish_date>2000-12-09</publish_date>
      <description>Microsoft's .NET initiative is explored in 
      detail in this deep programmer's reference.</description>
   </book>
   <book id="bk111">
      <author>O'Brien, Tim</author>
      <title>MSXML3: A Comprehensive Guide</title>
      <genre>Computer</genre>
      <price>36.95</price>
      <publish_date>2000-12-01</publish_date>
      <description>The Microsoft MSXML3 parser is covered in 
      detail, with attention to XML DOM interfaces, XSLT processing, 
      SAX and more.</description>
   </book>
   <book id="bk112">
      <author>Galos, Mike</author>
      <title>Visual Studio 7: A Comprehensive Guide</title>
      <genre>Computer</genre>
      <price>49.95</price>
      <publish_date>2001-04-16</publish_date>
      <description>Microsoft Visual Studio 7 is explored in depth,
      looking at how Visual Basic, Visual C++, C#, and ASP+ are 
      integrated into a comprehensive development 
      environment.</description>
   </book>
</catalog>
```
<script>
const books = `@input(1)`
@input(0)
</script>


``` js
const xsltString = `
<xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform">
<xsl:template match="/">
  <h2>Katalog</h2>
  <ul>
    <xsl:for-each select="catalog/book[price &gt; 10]">
      <li>
        <b><xsl:value-of select="title"/></b>
        â€” <xsl:value-of select="author"/> â€”
        <xsl:value-of select="price"/> â‚¬
      </li>
    </xsl:for-each>
  </ul>
</xsl:template>
</xsl:stylesheet>`;

// XML & XSLT parsen
const parser = new DOMParser();
const xml = parser.parseFromString(xmlString, "text/xml");
const xslt = parser.parseFromString(xsltString, "text/xml");

// Transformation
const processor = new XSLTProcessor();
processor.importStylesheet(xslt);
const fragment = processor.transformToFragment(xml, document);
const serializer = new XMLSerializer();
const htmlString = serializer.serializeToString(fragment);

console.html(htmlString);
```
``` xml  -Books.xml
<catalog>
   <book id="bk101">
      <author>Gambardella, Matthew</author>
      <title>XML Developer's Guide</title>
      <genre>Computer</genre>
      <price>44.95</price>
      <publish_date>2000-10-01</publish_date>
      <description>An in-depth look at creating applications 
      with XML.</description>
   </book>
   <book id="bk102">
      <author>Ralls, Kim</author>
      <title>Midnight Rain</title>
      <genre>Fantasy</genre>
      <price>5.95</price>
      <publish_date>2000-12-16</publish_date>
      <description>A former architect battles corporate zombies, 
      an evil sorceress, and her own childhood to become queen 
      of the world.</description>
   </book>
   <book id="bk103">
      <author>Corets, Eva</author>
      <title>Maeve Ascendant</title>
      <genre>Fantasy</genre>
      <price>5.95</price>
      <publish_date>2000-11-17</publish_date>
      <description>After the collapse of a nanotechnology 
      society in England, the young survivors lay the 
      foundation for a new society.</description>
   </book>
   <book id="bk104">
      <author>Corets, Eva</author>
      <title>Oberon's Legacy</title>
      <genre>Fantasy</genre>
      <price>5.95</price>
      <publish_date>2001-03-10</publish_date>
      <description>In post-apocalypse England, the mysterious 
      agent known only as Oberon helps to create a new life 
      for the inhabitants of London. Sequel to Maeve 
      Ascendant.</description>
   </book>
   <book id="bk105">
      <author>Corets, Eva</author>
      <title>The Sundered Grail</title>
      <genre>Fantasy</genre>
      <price>5.95</price>
      <publish_date>2001-09-10</publish_date>
      <description>The two daughters of Maeve, half-sisters, 
      battle one another for control of England. Sequel to 
      Oberon's Legacy.</description>
   </book>
   <book id="bk106">
      <author>Randall, Cynthia</author>
      <title>Lover Birds</title>
      <genre>Romance</genre>
      <price>4.95</price>
      <publish_date>2000-09-02</publish_date>
      <description>When Carla meets Paul at an ornithology 
      conference, tempers fly as feathers get ruffled.</description>
   </book>
   <book id="bk107">
      <author>Thurman, Paula</author>
      <title>Splish Splash</title>
      <genre>Romance</genre>
      <price>4.95</price>
      <publish_date>2000-11-02</publish_date>
      <description>A deep sea diver finds true love twenty 
      thousand leagues beneath the sea.</description>
   </book>
   <book id="bk108">
      <author>Knorr, Stefan</author>
      <title>Creepy Crawlies</title>
      <genre>Horror</genre>
      <price>4.95</price>
      <publish_date>2000-12-06</publish_date>
      <description>An anthology of horror stories about roaches,
      centipedes, scorpions  and other insects.</description>
   </book>
   <book id="bk109">
      <author>Kress, Peter</author>
      <title>Paradox Lost</title>
      <genre>Science Fiction</genre>
      <price>6.95</price>
      <publish_date>2000-11-02</publish_date>
      <description>After an inadvertant trip through a Heisenberg
      Uncertainty Device, James Salway discovers the problems 
      of being quantum.</description>
   </book>
   <book id="bk110">
      <author>O'Brien, Tim</author>
      <title>Microsoft .NET: The Programming Bible</title>
      <genre>Computer</genre>
      <price>36.95</price>
      <publish_date>2000-12-09</publish_date>
      <description>Microsoft's .NET initiative is explored in 
      detail in this deep programmer's reference.</description>
   </book>
   <book id="bk111">
      <author>O'Brien, Tim</author>
      <title>MSXML3: A Comprehensive Guide</title>
      <genre>Computer</genre>
      <price>36.95</price>
      <publish_date>2000-12-01</publish_date>
      <description>The Microsoft MSXML3 parser is covered in 
      detail, with attention to XML DOM interfaces, XSLT processing, 
      SAX and more.</description>
   </book>
   <book id="bk112">
      <author>Galos, Mike</author>
      <title>Visual Studio 7: A Comprehensive Guide</title>
      <genre>Computer</genre>
      <price>49.95</price>
      <publish_date>2001-04-16</publish_date>
      <description>Microsoft Visual Studio 7 is explored in depth,
      looking at how Visual Basic, Visual C++, C#, and ASP+ are 
      integrated into a comprehensive development 
      environment.</description>
   </book>
</catalog>
```
<script>
const xmlString = `@input(1)`;
@input
"LIA: stop"
</script>


    {{6}}
<section>


**XPath - Navigation durch XML-BÃ¤ume:**

```xpath
/* Alle Buchtitel */
//book/title

/* BÃ¼cher nach 1980 */
//book[year > 1980]/title

/* BÃ¼cher von Kernighan */
//book[authors/author = "Brian Kernighan"]/title

/* BÃ¼cher Ã¼ber $50 */
//book[price > 50]/@isbn

/* Zweites Buch */
//book[2]

/* BÃ¼cher mit mehr als einem Autor */
//book[count(authors/author) > 1]
```


**XQuery - SQL fÃ¼r XML:**

```xquery
for $book in //book
where $book/year > 1980 and $book/price < 100
order by $book/price descending
return
  <result>
    <title>{$book/title/text()}</title>
    <cost>{$book/price/text()}</cost>
  </result>
```

**Vergleich:**

- **CSV:** Keine Query-Sprache (nur externe Tools)
- **JSON:** JSONPath (limitiert, nicht standardisiert)
- **XML:** XPath/XQuery (mÃ¤chtig, aber komplex)

> **Das Problem:** Die Macht von XQuery rechtfertigt selten den XML-Overhead.

</section>


    --{{8}}--
Warum existiert XML noch? Legacy! SOAP-APIs aus den 2000ern, Microsoft Office-Formate, SVG-Grafiken, RSS-Feeds - Ã¼berall wo KompatibilitÃ¤t wichtiger ist als Effizienz. Aber neue Projekte? Die starten mit JSON, nicht XML. Das ist die Lektion: Perfektion ist der Feind des Guten.

    {{8}}
<section>

### ğŸ¯ Wann XML verwenden - Wann nicht

**âœ… XML ist perfekt fÃ¼r:**

- **Legacy-Systeme** mit SOAP-APIs (keine Wahl)
- **Dokumenten-Workflows** mit komplexer Validation (DocBook, DITA)
- **Office-Formate** (.docx, .xlsx sind ZIP-Archive mit XML)
- **SVG/MathML** - Grafiken und Formeln als Vektordaten
- **RSS/Atom Feeds** - etablierter Standard
- **Konfigurationsdateien** mit Schema-Validierung (Maven pom.xml, ANT)

**âŒ XML ist schlecht fÃ¼r:**

- **REST-APIs** (JSON ist 3-6x effizienter)
- **Real-time Kommunikation** (Parsing-Overhead zu hoch)
- **Mobile Apps** (Bandbreite & Battery verschwendet)
- **NoSQL-Datenbanken** (JSON-nativer)
- **Microservices** (zu verbose fÃ¼r Service-Mesh)

> **Professor Freinets Regel:** XML nur wo MÃœSSEN (Legacy), nie wo KÃ–NNEN (neue Projekte)!

</section>

    --{{9}}--
Zum Abschluss eine historische Perspektive: XML war die Antwort auf CSV-Chaos in den 90ern. Es brachte Ordnung, aber zum Preis der PraktikabilitÃ¤t. JSON lernte aus XMLs Fehlern: genug Struktur fÃ¼r Maschinen, genug Lesbarkeit fÃ¼r Menschen. Das ist Evolution in Reinform - und wir sind dabei, sie zu beobachten.

    {{9}}
<section>

### ğŸ“œ Die XML-Lektion fÃ¼r Architekten

**Was XML richtig machte:**

- âœ… Hierarchische Struktur (besser als flaches CSV)
- âœ… Schema-Validierung (IntegritÃ¤t!)
- âœ… Namespaces (Kollisions-Vermeidung)
- âœ… MÃ¤chtige Query-Sprachen

**Was XML falsch machte:**

- âŒ Zu verbose (3-6x Overhead)
- âŒ Zu komplex (XSD ist monstrÃ¶s)
- âŒ Parsing-Performance (10-50x langsamer als JSON)
- âŒ Schlechte Developer-Experience

**Die Architektur-Lektion:**

> **"Perfektion ist der Feind des Guten."**\
> XML versuchte, ALLES richtig zu machen - und wurde dadurch fÃ¼r VIELES unbrauchbar.

**JSON gewann nicht durch Perfektion, sondern durch:**

- Einfachheit (5 Minuten zum Lernen)
- Effizienz (nativ in JavaScript)
- Pragmatismus (gut genug fÃ¼r 95% der FÃ¤lle)

Das ist die Lektion fÃ¼r Datenbankarchitektur: **Optimiere fÃ¼r den Normalfall, nicht den Extremfall.**

</section>

### JSON - Das GoldlÃ¶ckchen-Format ğŸ»âœ¨

    --{{0}}--
JSON - JavaScript Object Notation - ist das Format, das den Sweet Spot zwischen CSV und XML gefunden hat. Nicht zu simpel, nicht zu komplex - genau richtig. Als praxisorientierter Architekt sage ich Ihnen: JSON ist das Format, das Sie in 5 Minuten lernen und fÃ¼r die nÃ¤chsten 10 Jahre nutzen werden.

    {{0}}
<section>

**Was ist JSON eigentlich?**

JSON steht fÃ¼r **JavaScript Object Notation** - ein textbasiertes Format fÃ¼r **strukturierte Daten** mit minimalem Overhead.

**Erfunden:** 2001 von Douglas Crockford\
**Ursprung:** Subset von JavaScript (aber sprachunabhÃ¤ngig!)\
**Philosophie:** *"So einfach wie mÃ¶glich, aber nicht einfacher"*

**Die 5-Minuten-Garantie:** Nach diesem Abschnitt kÃ¶nnen Sie JSON lesen, schreiben und verstehen!

</section>

    --{{1}}--
Lassen Sie uns mit der Anatomie beginnen. JSON hat exakt SECHS Datentypen - keine mehr, keine weniger. Zahlen, Strings, Booleans, null, Arrays und Objekte. Das wars. Diese bewusste BeschrÃ¤nkung macht JSON lernbar, aber nicht limitiert.

    {{1}}
<section>

### ğŸ” JSON-Anatomie: Die 6 Datentypen

```json
{
  "string": "Hallo Welt",           // Text in AnfÃ¼hrungszeichen
  "number": 42,                      // Integer oder Float (kein Unterschied!)
  "boolean": true,                   // true oder false (kleingeschrieben!)
  "null": null,                      // Explizites "nichts"
  "array": [1, 2, 3],               // Geordnete Liste
  "object": {                        // Key-Value-Paare
    "nested": "Verschachtelung mÃ¶glich!"
  }
}
```

**Wichtige Regeln:**

- **Keys** MÃœSSEN in doppelten AnfÃ¼hrungszeichen: `"name"` âœ… nicht `name` âŒ
- **Strings** nur mit doppelten AnfÃ¼hrungszeichen: `"text"` âœ… nicht `'text'` âŒ
- **Keine trailing commas:** `[1, 2, 3]` âœ… nicht `[1, 2, 3,]` âŒ
- **Keine Kommentare:** JSON ist pures Datenformat (Kommentare = Parsing-Error!)

</section>

    --{{2}}--
Jetzt wird es praktisch! Hier ist derselbe Titanic-Passagier in CSV, JSON und XML. Sehen Sie den Unterschied? CSV ist flach, XML ist verbose, JSON ist strukturiert aber lesbar. Beachten Sie: JSON kann Verschachtelung (Name-Objekt), Arrays (Tickets) und verschiedene Typen - alles was CSV nicht kann, ohne XMLs Overhead!

    {{2}}
<section>

### ğŸ“Š Vergleich: CSV vs. JSON vs. XML (Titanic-Passagier)

**CSV (flach, keine Struktur):**
```csv
PassengerId,Survived,Pclass,Name,Sex,Age,Fare,Cabin,Embarked
2,1,1,"Cumings, Mrs. John Bradley",female,38,71.2833,C85,C
```

**JSON (strukturiert, lesbar):**

```json
{
  "passengerId": 2,
  "survived": true,
  "class": 1,
  "name": {
    "family": "Cumings",
    "given": "Florence Briggs",
    "title": "Mrs.",
    "husband": "John Bradley"
  },
  "demographics": {
    "sex": "female",
    "age": 38
  },
  "ticket": {
    "number": "PC 17599",
    "fare": 71.28,
    "cabin": "C85",
    "embarked": "Cherbourg"
  }
}
```

**XML (verbose, bÃ¼rokratisch):**

```xml
<passenger id="2">
  <survived>true</survived>
  <class>1</class>
  <name family="Cumings" given="Florence Briggs" title="Mrs.">
    <husband>John Bradley</husband>
  </name>
  <demographics sex="female" age="38"/>
  <ticket number="PC 17599" fare="71.28" cabin="C85" embarked="Cherbourg"/>
</passenger>
```

**Size-Vergleich:** CSV: 87B | JSON: 285B (3.3x) | XML: 312B (3.6x)

ğŸ’¡ **Merke:** JSON hat mehr Overhead als CSV, aber **deutlich weniger** als XML - und dafÃ¼r Struktur!

</section>

    --{{3}}--
Ein kritischer Punkt: JSON hat keine Datumstypen! Das ist kein Fehler, sondern Design. JSON bleibt bewusst einfach und Ã¼berlÃ¤sst Interpretation der Anwendung. Daher sehen Sie Dates oft als ISO-Strings. Auch die Zahl 42 vs "42" - JSON unterscheidet nicht zwischen Integer und Float, alles ist "number". Das vereinfacht Parser, aber Typsicherheit kommt von auÃŸen (TypeScript, JSON Schema).

    {{3}}
<section>

### âš ï¸ JSON-Fallen: Was fehlt?

**1. Keine Datumstypen:**

```json
{
  "date": "2023-10-17",           // String, kein Date!
  "timestamp": 1697500800,        // Unix-Timestamp als Zahl
  "iso": "2023-10-17T10:00:00Z"   // ISO 8601 String (Ã¼blich)
}
```

**2. Keine Integer vs. Float Unterscheidung:**

```json
{
  "integer": 42,      // Beides ist "number"
  "float": 42.0,      // Parser entscheidet!
  "scientific": 4.2e1 // Auch valid
}
```

**3. Keine BinÃ¤rdaten:**

```json
{
  "image": "base64encodedstring..."  // Muss als String kodiert werden
}
```

**4. Keine Kommentare:**

```json
{
  // "comment": "Das ist ein Error!"  âŒ
  "_comment": "Workaround: Fake-Key"  âœ…
}
```

**5. Encoding muss UTF-8 sein:**
- JSON Standard erlaubt NUR UTF-8 (oder UTF-16/UTF-32)
- Kein Latin-1, kein Windows-1252 â†’ weniger Chaos als bei CSV!

</section>

    --{{4}}--
Jetzt die gute Nachricht: JSON ist unglaublich praktisch in der Praxis. Jede moderne Programmiersprache hat native oder near-native Support. JavaScript? Es ist literale Syntax! Python? Ein dict ist schon JSON. Parsing ist 10-50x schneller als XML. Und Developer Experience? Sublime - keine XSD-Monster, keine DTDs, einfach schreiben und fertig.

    {{4}}
<section>

### âœ… JSON in der Praxis: Warum es dominiert

**Native JavaScript-Integration:**

```javascript
// JSON ist literale JavaScript-Syntax!
const person = {
  "name": "Alice",
  "age": 30
};

// Parsing & Serialisierung built-in
const jsonString = JSON.stringify(person);
const parsed = JSON.parse(jsonString);

console.log(jsonString);
```
<script>
@input
""
</script>

**Python (near-native):**

```python @PyScript.repl
import json

# Dict â†’ JSON
data = {"name": "Alice", "age": 30}
json_str = json.dumps(data)

# JSON â†’ Dict  
parsed = json.loads(json_str)

print(json_str)
```

**REST-APIs Standard:**

- 95% aller modernen APIs nutzen JSON
- `Content-Type: application/json`
- Kleinere Payloads als XML (3x Faktor)

**NoSQL-Datenbanken:**

- MongoDB speichert BSON (Binary JSON)
- CouchDB, RethinkDB, Firebase - alle JSON-nativ
- Queries direkt auf JSON-Struktur

</section>


    --{{6}}--
Die JSON-Erfolgsformel in einem Satz: Es ist einfach genug, dass Sie es in 5 Minuten lernen, aber mÃ¤chtig genug fÃ¼r komplexe APIs. Kein Zufall, dass REST-APIs JSON nutzen, nicht XML. Developer Experience schlÃ¤gt formale Perfektion - das ist die Lektion!

    {{6}}
<section>

### ğŸ¯ Wann JSON verwenden - Wann nicht

**âœ… JSON ist perfekt fÃ¼r:**

- **REST-APIs** (de facto Standard seit 2010)
- **Web-Anwendungen** (native JavaScript-Integration)
- **NoSQL-Datenbanken** (MongoDB, CouchDB, Firebase)
- **Konfigurationsdateien** (package.json, tsconfig.json)
- **Data Science** (wenn Struktur wichtiger als Size)
- **Microservices-Kommunikation** (schnell, kompakt)

**âŒ JSON ist schlecht fÃ¼r:**

- **BinÃ¤rdaten** (Base64-Overhead 33%)
- **Sehr groÃŸe Datasets** (CSV ist 3x kompakter)
- **Streaming-Daten** (keine partielle Parsing-UnterstÃ¼tzung)
- **Komplexe Validierung** (JSON Schema ist optional, nicht native)
- **Kommentare notwendig** (YAML oder TOML besser)

**ğŸ¤” JSON ist OK, aber nicht optimal fÃ¼r:**

- **Human-Editing** (YAML ist lesbarer ohne Quotes/Commas)
- **Typsichere APIs** (Protobuf oder gRPC besser)
- **Extreme Performance** (MessagePack, BSON schneller)

> **Professor Freinets Regel:** JSON fÃ¼r alles wo Menschen UND Maschinen lesen - das sind 90% aller FÃ¤lle!

</section>

    --{{7}}--
Zum Abschluss: JSON ist kein Zufall - es ist Evolution. CSV war zu simpel, XML zu komplex, JSON fand die Balance. Das ist die Architektur-Lektion: Erfolgreiche Technologien optimieren nicht fÃ¼r Perfektion, sondern fÃ¼r Adoption. JSON gewann, weil es einfach genug war, dass jeder Entwickler es ohne Handbuch versteht. Das ist der Benchmark fÃ¼r alle zukÃ¼nftigen Datenformate!

    {{7}}
<section>

### ğŸ“œ Die JSON-Lektion fÃ¼r Architekten

**Was JSON richtig machte:**

- âœ… **Einfachheit:** 6 Datentypen, 5 Minuten Lernzeit
- âœ… **Lesbarkeit:** SelbsterklÃ¤rend ohne Schema
- âœ… **Performance:** 10-50x schneller als XML
- âœ… **Adoption:** Native in JavaScript, near-native Ã¼berall
- âœ… **Pragmatismus:** Gut genug fÃ¼r 95% der FÃ¤lle

**Was JSON bewusst opferte:**

- âŒ Keine Kommentare (Daten â‰  Dokumentation)
- âŒ Keine Dates (Interpretation bleibt bei Anwendung)
- âŒ Kein natives Schema (JSON Schema optional)
- âŒ Keine BinÃ¤rdaten (Base64-Workaround)

**Die Architektur-Lektion:**

> **"Simplicity is the ultimate sophistication."** (Leonardo da Vinci)\
> JSON gewann nicht durch Features, sondern durch **Fehlende KomplexitÃ¤t**.

**Erfolgsformel:**

1. **Developer Experience > Formale Perfektion**
2. **Adoption > Theoretische Ãœberlegenheit**
3. **"Gut genug" > "Alles richtig"**

Das ist die DNA erfolgreicher Technologien: **Optimiere fÃ¼r den Normalfall, akzeptiere SchwÃ¤chen im Extremfall.**

</section>


``` js
fetch('https://restcountries.com/v3.1/name/germany')
//fetch('https://jsonplaceholder.typicode.com/users/1')
//fetch('https://api.github.com/repos/microsoft/vscode')
//fetch('https://api.open-meteo.com/v1/forecast?latitude=52.52&longitude=13.41&current=temperature_2m')
  .then(response => response.json())
  .then(data => console.log(JSON.stringify(data, null, 2)))
  .catch(error => console.error("Ups", error.message))
```
<script>
@input
""
</script>


### YAML - JSON fÃ¼r Menschen ğŸ“

    --{{0}}--
YAML - YAML Ain't Markup Language - ist JSONs menschenfreundlicher Cousin. Es wurde 2001 entwickelt, kurz nach JSON, mit einem klaren Ziel: Konfigurationsdateien, die Menschen gerne schreiben. Weniger Syntax-Noise, mehr Lesbarkeit. Docker Compose, Kubernetes, GitHub Actions - Ã¼berall wo Konfiguration king ist, finden Sie YAML.

    {{0}}
<section>

**Was ist YAML?**

YAML = **YAML Ain't Markup Language** (rekursives Akronym)\
**Erfunden:** 2001 (parallel zu JSON)\
**Philosophie:** *"Human-readable data serialization"*\
**Superset von JSON:** Jedes JSON ist valides YAML!

**Der Kern-Unterschied zu JSON:**

- âŒ Keine geschweiften Klammern `{}`
- âŒ Keine eckigen Klammern `[]` (optional)
- âŒ Keine AnfÃ¼hrungszeichen fÃ¼r Strings (meist)
- âŒ Keine Kommas
- âœ… EinrÃ¼ckung definiert Struktur (wie Python!)
- âœ… Kommentare erlaubt (`#`)

</section>

    --{{1}}--
Lassen Sie uns den direkten Vergleich sehen. Hier ist dieselbe Kubernetes-Config in JSON und YAML. Sehen Sie den Unterschied? JSON ist voller Syntax-Noise - Klammern, Quotes, Kommas. YAML ist clean - reine Daten, minimale Syntax. Das ist der Grund, warum DevOps YAML liebt: Sie schreiben Konfiguration, keine Parsing-Anweisungen!

    {{1}}
<section>

### ğŸ“Š JSON vs. YAML - Derselbe Inhalt

**JSON (verbose, viele Sonderzeichen):**

```json
{
  "apiVersion": "v1",
  "kind": "Service",
  "metadata": {
    "name": "my-service",
    "labels": {
      "app": "myapp"
    }
  },
  "spec": {
    "ports": [
      {
        "port": 80,
        "targetPort": 8080
      }
    ],
    "selector": {
      "app": "myapp"
    }
  }
}
```

**YAML (clean, lesbar):**

```yaml
apiVersion: v1
kind: Service
metadata:
  name: my-service
  labels:
    app: myapp
spec:
  ports:
    - port: 80
      targetPort: 8080
  selector:
    app: myapp
```

**Unterschied:** 

- JSON: 253 Zeichen, 18 Zeilen mit Syntax-Noise
- YAML: 158 Zeichen, 12 Zeilen ohne Clutter
- **37% kompakter, deutlich lesbarer!**

ğŸ’¡ **Merke:** YAML = JSON ohne Syntax-Overhead fÃ¼r menschliche Augen!

</section>

    --{{2}}--
YAML hat aber auch TÃ¼cken! EinrÃ¼ckung mit Spaces ist Pflicht - ein Tab bricht alles. Mehrdeutigkeiten gibt es auch: "yes", "no", "on", "off" werden zu Booleans geparsed, nicht Strings. Und die Spec ist riesig - YAML 1.2 hat Features, die kaum jemand nutzt. Daher: YAML fÃ¼r Konfig-Dateien, JSON fÃ¼r APIs. Das ist die Faustregel!

    {{2}}
<section>

### âš ï¸ YAML-Fallen & Best Practices

**1. EinrÃ¼ckung ist kritisch:**

```yaml
# âœ… RICHTIG (2 Spaces)
parent:
  child: value

# âŒ FALSCH (Tabs oder inkonsistente Spaces)
parent:
    child: value  # 4 Spaces â†’ Parsing-Error mÃ¶glich!
```

**2. Implizite Typen (kÃ¶nnen Ã¼berraschen):**

```yaml
# Vorsicht: Diese werden zu Booleans!
boolean_yes: yes      # â†’ true
boolean_no: no        # â†’ false
boolean_on: on        # â†’ true

# Strings explizit machen:
string_yes: "yes"     # â†’ "yes" (String)
string_jaa: jaa       # â†’ "no" (String)
```

**3. Mehrzeilige Strings:**

```yaml
# | = ZeilenumbrÃ¼che behalten
description: |
  Dies ist eine
  mehrzeilige
  Beschreibung.

# > = ZeilenumbrÃ¼che werden zu Spaces
summary: >
  Langer Text der
  als eine Zeile
  behandelt wird.
```

**4. Anker & Aliase (Wiederverwendung):**

```yaml
defaults: &default_settings
  timeout: 30
  retries: 3

service_a:
  <<: *default_settings  # Ãœbernimmt defaults
  name: ServiceA

service_b:
  <<: *default_settings
  name: ServiceB
```

</section>

    --{{3}}--
Wann nutzen Sie YAML, wann JSON? Die Antwort ist einfach: YAML fÃ¼r Dateien, die Menschen schreiben und lesen - Konfiguration, CI/CD Pipelines, Infrastructure-as-Code. JSON fÃ¼r Maschinen - APIs, Datenbank-Export, programmatische Generierung. Das ist kein Zufall: Docker Compose, Kubernetes, Ansible, GitHub Actions - alles YAML. REST-APIs? Alle JSON. Die richtige Tool fÃ¼r den richtigen Job!

    {{3}}
<section>

### ğŸ¯ Wann YAML - Wann JSON?

**âœ… YAML ist perfekt fÃ¼r:**

- **Konfigurationsdateien** (docker-compose.yml, .gitlab-ci.yml)
- **Infrastructure-as-Code** (Kubernetes Manifests, Ansible Playbooks)
- **CI/CD Pipelines** (GitHub Actions, CircleCI)
- **Menschliches Editing** (weniger Syntax-Fehler)
- **Dokumentation** (Kommentare erlaubt!)

**âœ… JSON ist besser fÃ¼r:**

- **REST-APIs** (maschinenlesbar, schnelles Parsing)
- **Programmatische Generierung** (keine EinrÃ¼ckung-Probleme)
- **Datenbank-Export** (klar definierte Struktur)
- **Browser-Kommunikation** (native JavaScript-UnterstÃ¼tzung)

**Die Faustregel:**

| Kriterium           | YAML       | JSON      |
| ------------------- | ---------- | --------- |
| **Geschrieben von** | Menschen   | Maschinen |
| **Gelesen von**     | Menschen   | Maschinen |
| **Use Case**        | Config     | Data      |
| **Kommentare**      | âœ… Ja      | âŒ Nein   |
| **Lesbarkeit**      | â­â­â­â­â­ | â­â­â­    |
| **Parsing-Speed**   | â­â­       | â­â­â­â­  |

> **Professor Freinets Regel:** YAML fÃ¼r Config-Files die du editierst, JSON fÃ¼r Data-Transfer den Maschinen verarbeiten!

</section>

    --{{4}}--
Zusammenfassung: YAML ist JSONs Antwort auf das Lesbarkeits-Problem. Es opfert Parsing-Speed fÃ¼r Developer-Experience. Das ist kein Bug, sondern Feature - denn Konfigurationsdateien werden einmal geschrieben, tausendmal gelesen. Optimiere fÃ¼r den Leser, nicht den Parser. Das ist die YAML-Philosophie in einem Satz!

    {{4}}
<section>

### ğŸ“œ Die YAML-Lektion

**YAML's Trade-offs:**

- âœ… **Lesbarkeit:** Keine Syntax-Noise â†’ 37% kompakter
- âœ… **Kommentare:** Dokumentation direkt in Config
- âœ… **DRY:** Anker/Aliase vermeiden Duplikation
- âŒ **Parsing:** 2-5x langsamer als JSON
- âŒ **Mehrdeutigkeiten:** `yes`/`no` werden zu Booleans
- âŒ **EinrÃ¼ckung:** Ein falscher Space bricht alles

**Die Evolution:**

```
CSV (1970er) â†’ zu simpel
XML (1990er) â†’ zu komplex  
JSON (2001)  â†’ maschinenfreundlich
YAML (2001)  â†’ menschenfreundlich
```

**Das Prinzip:**

> **"Optimiere fÃ¼r die HÃ¤ufigkeit der Operation."**\
> Config wird 1x geschrieben, 1000x gelesen â†’ Optimiere fÃ¼r Leser!\
> API-Data wird 1000x generiert, 1000x geparsed â†’ Optimiere fÃ¼r Parser!

YAML und JSON koexistieren, weil sie **unterschiedliche Probleme** lÃ¶sen!

</section>


## ğŸ¯ Fazit & Ausblick: Von Rohdaten zu strukturierten Systemen

    --{{0}}--
Lassen Sie uns die Reise zusammenfassen. Wir haben heute die Grundlagen gelegt - nicht nur als historische Trivia, sondern als funktionale Analyse. Die DIKW-Pyramide zeigte uns: Daten ohne Kontext sind wertlos. Die historischen Beispiele zeigten: Jedes moderne DB-Feature hat einen VorlÃ¤ufer. Und die Datenformate zeigten: Es gibt keinen AlleskÃ¶nner - nur Trade-offs.

    {{0}}
<section>

### ğŸ“š Was Sie heute gelernt haben

**1. Die DIKW-Pyramide als Analyserahmen:**

- **Data:** Rohe Fakten (Federn zÃ¤hlen, Bytes speichern)
- **Information:** Kontextualisierte Daten (KriegshÃ¤uptling-Status)
- **Knowledge:** Vernetzte Informationen (GefahreneinschÃ¤tzung)
- **Wisdom:** HandlungsfÃ¤higkeit (Entscheidung treffen)

â†’ Datenbanken bewegen sich zwischen Data und Information!

**2. Historische DNA moderner Systeme:**

- **Pacioli's Soll/Haben** â†’ ACID-Transaktionen (Session L15!)
- **Karteikarten-Katalog** â†’ B-Tree-Indizes (Session L16!)
- **SchiffstagebÃ¼cher** â†’ Write-Ahead-Logs (Session L22!)
- **Hollerith-Lochkarten** â†’ Schema-Enforcement
- **Tontafeln** â†’ Append-Only-Logs

â†’ Keine Konzepte sind wirklich neu - nur automatisiert!


**4. Datenformate und ihre Trade-offs:**

```
CSV:  â­â­ | â­  | â­â­â­ | â­â­   | â­â­â­â­  â†’ Schnell, aber strukturlos
JSON: â­â­â­ | â­â­ | â­â­â­ | â­â­â­â­ | â­â­â­â­  â†’ Pragmatischer Allrounder
XML:  â­â­â­â­â­ | â­â­â­â­ | â­â­ | â­â­â­â­ | â­â­    â†’ Perfekt, aber unpraktisch
YAML: â­â­â­ | â­â­ | â­â­â­ | â­â­â­â­ | â­â­     â†’ JSON fÃ¼r Menschen
```

â†’ Kein Format ist "das Beste" - nur "das Beste fÃ¼r X"!

</section>

    --{{1}}--
Aber jetzt kommt der kritische Punkt: Alle diese Formate - CSV, JSON, XML, YAML - haben ein fundamentales Problem. Sie sind *Dateien*. Und Dateien sind dumm. Sie wissen nichts von Transaktionen, nichts von Indizes, nichts von Concurrency-Control. Wenn zwei Prozesse gleichzeitig schreiben? Datenverlust. Wenn Sie nach einem Feld suchen? Lineares Scannen. Wenn Sie IntegritÃ¤t garantieren wollen? Beten Sie!

    {{1}}
<section>

### ğŸš¨ Das fundamentale Problem: Dateien sind dumm

**Was Dateien NICHT kÃ¶nnen:**

âŒ **Schnelles Suchen:** Linear Scan durch 1 GB CSV fÃ¼r eine Zeile?\
âŒ **Transaktionen:** Zwei gleichzeitige Writes â†’ Einer verliert!\
âŒ **Indizes:** Jede Query liest ALLES (O(n) statt O(log n))\
âŒ **IntegritÃ¤t:** Kein Foreign-Key-Check, keine Constraints\
âŒ **Concurrency:** Lock the whole file? Performance-Killer!\
âŒ **Recovery:** File korrupt? Alles weg!

**Real-World Horror-Szenario:**

```python
# Zwei Prozesse schreiben gleichzeitig in users.csv
# Prozess A: FÃ¼gt "Alice" ein
# Prozess B: FÃ¼gt "Bob" ein
# Ergebnis: Datei korrupt, beide EintrÃ¤ge kaputt! ğŸ’¥
```

**Die Frage, die Sie sich stellen sollten:**

> "Wenn CSV so simpel ist und JSON so pragmatisch - warum brauchen wir Ã¼berhaupt Datenbanken?"

**Die Antwort:** Weil Dateien **Datenhaltung** sind, aber keine **Datenverwaltung**!

</section>

    --{{2}}--
Und hier beginnt die nÃ¤chste Phase unserer Reise. Session L2 fÃ¼hrt Key-Value Stores ein - das einfachste Datenbankparadigma. Denken Sie an ein gigantisches Hash-Map in Memory: SchlÃ¼ssel â†’ Wert, O(1) Zugriff, Transaktionen, Persistierung. Redis, Memcached, DynamoDB - Milliarden von Requests pro Tag. Aber auch sie haben Grenzen: Keine Queries, keine Relationen, keine Joins. Das ist die Evolution in Aktion!

    {{2}}
<section>

### ğŸ”® Ausblick: Session L2 - Key-Value Stores

**Die nÃ¤chste Evolutionsstufe:**

Wir haben gelernt: CSV ist zu simpel, XML ist zu komplex, JSON ist genau richtig fÃ¼r *Daten*.\
**Aber:** Alle sind **Dateien** ohne *Verwaltung*!

**Key-Value Stores lÃ¶sen DAS Problem:**

```
Problem                  â†’ LÃ¶sung (Key-Value)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Langsames Suchen        â†’ Hash-Map (O(1))
Keine Transaktionen     â†’ ACID-Garantien
Kein Concurrency        â†’ Lock-free Reads
Keine Persistierung     â†’ Write-Ahead-Log
Linear Scan             â†’ Direkt-Zugriff
```

</section>

    --{{3}}--
Zum Abschluss die wichtigste Lektion: Datenbankarchitektur ist KEINE Religion. Es gibt kein "bestes" System, nur "best fÃ¼r diesen Use-Case". CSV fÃ¼r schnelle Exports. JSON fÃ¼r APIs. XML fÃ¼r Legacy. Und bald: Key-Value fÃ¼r Caching, Document fÃ¼r FlexibilitÃ¤t, Column fÃ¼r Analytics, Relational fÃ¼r IntegritÃ¤t, Graph fÃ¼r Beziehungen. Jedes Paradigma ist eine Antwort auf spezifische SchwÃ¤chen des vorherigen. Das ist Evolution - und Sie sind jetzt in der Lage, sie zu analysieren!

    {{3}}
<section>

### ğŸ“ Die Meta-Lektion: Trade-offs akzeptieren

**Warum diese Vorlesung NICHT mit SQL startete:**

Viele Datenbank-Kurse beginnen mit relationalen Systemen und SQL.\
**Das Problem:** Sie verstehen nicht, *warum* Relational gut ist - nur *dass* es gut ist.

**Unser Ansatz:**

```
Rohdaten (CSV)                  â†’ Verstehe das Problem
Key-Value (Redis)               â†’ Erste LÃ¶sung (schnell, simpel)
Document (MongoDB)              â†’ Zweite LÃ¶sung (flexibel)
(Wide) Column (Cassandra)       â†’ Dritte LÃ¶sung (analytisch)
Relational (PostgreSQL)         â†’ Vierte LÃ¶sung (formal korrekt)
Graph (Neo4j)                   â†’ FÃ¼nfte LÃ¶sung (semantisch)
```

**Jedes System ist die Antwort auf die SchwÃ¤chen des vorherigen!**

**Die 5 Vergleichsachsen als Kompass:**

- Sie haben jetzt ein **Werkzeug** zum Analysieren
- Am Ende: **VollstÃ¤ndige Ãœbersicht** aller Paradigmen
- Ziel: **EntscheidungsfÃ¤higkeit**, keine Dogmen!

</section>